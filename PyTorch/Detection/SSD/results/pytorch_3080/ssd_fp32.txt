DLL 2020-09-22 00:08:00.422859 - PARAMETER dataset path : /coco  epochs : 1  batch size : 24  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
Using seed = 6756
loading annotations into memory...
Done (t=0.36s)
creating index...
index created!
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
DLL 2020-09-22 00:09:19.139745 - () avg_img/sec : 101.96019656322028  med_img/sec : 101.97975270871453  min_img/sec : 98.9417102417928  max_img/sec : 102.68013929605307 
Done benchmarking. Total images: 4800	total time: 47.077	Average images/sec: 101.960	Median images/sec: 101.980
Training performance = 101.97975158691406 FPS
DLL 2020-09-22 00:09:19.189752 - (0,) time : 73.7301127910614 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-22 00:09:19.189886 - () total time : 73.7301127910614 
DLL 2020-09-22 00:09:19.189900 - () 
