DLL 2020-09-07 05:20:13.410984 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2020-09-07 05:20:13.816230 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2020-09-07 05:20:13.817654 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2020-09-07 05:20:13.819915 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2020-09-07 05:20:13.830632 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2020-09-07 05:20:13.840877 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2020-09-07 05:20:13.881632 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2020-09-07 05:20:13.920132 - PARAMETER dataset path : /coco  epochs : 1  batch size : 128  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0026  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
Using seed = 1698
loading annotations into memory...
Using seed = 7188
Using seed = 780
loading annotations into memory...
loading annotations into memory...
Done (t=0.45s)
creating index...
Done (t=0.44s)
creating index...
index created!
Done (t=0.45s)
creating index...
index created!
index created!
Using seed = 8661
loading annotations into memory...
Using seed = 4220
loading annotations into memory...
Using seed = 8445
loading annotations into memory...
Using seed = 914
Using seed = 5693
loading annotations into memory...
loading annotations into memory...
Done (t=0.44s)
creating index...
index created!
Done (t=0.47s)
creating index...
Done (t=0.46s)
creating index...
index created!
Done (t=0.45s)
creating index...
index created!
Done (t=0.47s)
creating index...
index created!
index created!
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
DLL 2020-09-07 05:23:47.647220 - () avg_img/sec : 204.93404001452197  med_img/sec : 205.1709441421884  min_img/sec : 199.61395417665287  max_img/sec : 207.04424832001234 
Done benchmarking. Total images: 25600	total time: 124.918	Average images/sec: 204.934	Median images/sec: 205.171
DLL 2020-09-07 05:23:47.647728 - () avg_img/sec : 204.75648151494656  med_img/sec : 205.0225855251696  min_img/sec : 199.1536021527115  max_img/sec : 206.85247487024304 
Done benchmarking. Total images: 25600	total time: 125.027	Average images/sec: 204.756	Median images/sec: 205.023
DLL 2020-09-07 05:23:47.647829 - () avg_img/sec : 204.85163840748515  med_img/sec : 205.11340857673218  min_img/sec : 199.27194875438076  max_img/sec : 206.9113092849977 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
Done benchmarking. Total images: 25600	total time: 124.968	Average images/sec: 204.852	Median images/sec: 205.113
DLL 2020-09-07 05:23:47.647956 - () total time : 198.5252182483673 
DLL 2020-09-07 05:23:47.647979 - () 
DLL 2020-09-07 05:23:47.648110 - () avg_img/sec : 204.89821348273753  med_img/sec : 205.1513446356849  min_img/sec : 199.2300197904873  max_img/sec : 206.9809493187263 
Done benchmarking. Total images: 25600	total time: 124.940	Average images/sec: 204.898	Median images/sec: 205.151
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-07 05:23:47.648324 - () total time : 198.52217173576355 
DLL 2020-09-07 05:23:47.648347 - () 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-07 05:23:47.648630 - () total time : 198.52245354652405 
DLL 2020-09-07 05:23:47.648654 - () 
DLL 2020-09-07 05:23:47.648678 - () avg_img/sec : 204.9431143917308  med_img/sec : 205.1945869117267  min_img/sec : 199.50157651573116  max_img/sec : 207.01598647941546 
Done benchmarking. Total images: 25600	total time: 124.913	Average images/sec: 204.943	Median images/sec: 205.195
DLL 2020-09-07 05:23:47.649509 - () avg_img/sec : 204.81793282010685  med_img/sec : 205.07842505158857  min_img/sec : 199.1383847514567  max_img/sec : 206.8362972871347 
Done benchmarking. Total images: 25600	total time: 124.989	Average images/sec: 204.818	Median images/sec: 205.078
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-07 05:23:47.649772 - () avg_img/sec : 204.79545439776834  med_img/sec : 205.07905160141706  min_img/sec : 199.18869968626728  max_img/sec : 206.86363329864227 
DLL 2020-09-07 05:23:47.649840 - () total time : 198.5251841545105 
DLL 2020-09-07 05:23:47.649874 - () 
Done benchmarking. Total images: 25600	total time: 125.003	Average images/sec: 204.795	Median images/sec: 205.079
DLL 2020-09-07 05:23:47.649823 - () avg_img/sec : 204.84593334667593  med_img/sec : 205.10694387756678  min_img/sec : 199.2632213429933  max_img/sec : 206.91800800660755 
Done benchmarking. Total images: 25600	total time: 124.972	Average images/sec: 204.846	Median images/sec: 205.107
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-07 05:23:47.650180 - () total time : 198.52418494224548 
DLL 2020-09-07 05:23:47.650204 - () 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-07 05:23:47.650371 - () total time : 198.52431416511536 
DLL 2020-09-07 05:23:47.650449 - () 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-07 05:23:47.650602 - () total time : 198.52312231063843 
DLL 2020-09-07 05:23:47.650627 - () 
Training performance = 1640.9173583984375 FPS
DLL 2020-09-07 05:23:47.782327 - (0,) time : 198.66789197921753 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-09-07 05:23:47.782613 - () total time : 198.66789197921753 
DLL 2020-09-07 05:23:47.782632 - () 
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
